In order to analyze the performance of the GNURadio blocks
discussed earlier a set of testcases were devised.

The metrics that the testcases were designed to test
were, firstly, the precision of the tag-placement in
the time domain in the presence of different disturbances,
secondly, the precision of the \gls{cfo} estimation
and finally the effective computational complexity.

\begin{subchapter}{Start-of-frame detection}
  The first testcase was designed to measures the quality
  of synchronisation when the signal is disturbed by,
  noise, frequency offsets or frequency selective channels.
  The respective results are shown in Figures \ref{img:results_time_sync_nois}
  to \ref{img:results_time_sync_chan}. \\

  All of these figures compare three different synchronization
  techniques:

  \begin{description}
    \item[Schmidl \& Cox]
      The \acrlong{schcox} Correlator and Tagger, as discussed in the
      previous chapter.

    \item[Burst \& Silence]
      A custom GNURadio block that detects a burst in input power
      followed by an equally long period of silence by calculating the
      average signal power in two consecutive windows and subtracting the
      power in the later window from the power of the earlier window.

      The noise floor affects both windows in a roughly equal manner
      and is thus canceled out.

    \item[Frequency Sweep]
      Another custom GNURadio block that mixes the input signal
      with a frequency sweep.

      The synchronization sequency consists of a complementary
      frequency sweep, such that the mixing of both will result
      in a constant frequency output.

      The constant frequency results in a constant phase difference
      between consecutive samples that is used for detection.
  \end{description}

  % TODO explain the rules

  \begin{subsubchapter}{AWGN Noise}
    Figure \ref{img:results_time_sync_nois} shows the effect of
    different \acrshortpl{snr} on the output of the synchronization
    methods.
    The histograms show the distribution of tag positions
    relative to the actual position of the synchronization
    sequence.
    For a perfect synchronization method the histogram would
    show a single peak in the ``$0$'' bin, indicating that every
    synchronization sequence was detected without even a single
    sample of offset.

    A particulary bad method would show a single peak in the
    ``missed'' bin, indicating that the sequence was missed by
    more than ten samples or not detected at all.

    \figurizefile{diagrams/results_time_sync_nois.tex}
                 {img:results_time_sync_nois}
                 {Detection time distributions for different \acrshortpl{snr}}
                 {1}{H}

    For high \glspl{snr} all of the tested methods produced
    usable results - tagging most preambles to within a few
    samples.

    For deacresing \glspl{snr} the results obtained by the
    frequency sweep based degraded rather quickly, missing most
    preambles at a \gls{snr} of just $\SI{0}{\deci\bel}$
    while the other methods still provide reliable output.

    The winning method in this test was the rather simple
    power-level based Burst \& Silence detector, dominating
    over the more complex Schmidl \& Cox detector.
    It should be noted however that the detection levels
    for all methods were tweaked to produce a minimal amount
    of false positives at low noise levels.

    When tweaking the parameters for different design criteria
    e.a. a minimal amount of false negatives the Schmidl \& Cox
    and Burst \& Silence show similar performance while
    the frequency sweep based approach always provides inferior
    results.
  \end{subsubchapter}

  \begin{subsubchapter}{Frequency offset}
    The second test was designed to test the effect a frequency offset
    between a transmitter and a receiver has on the detection accuracy
    of the respective algorithms.

    In this test the baseband signals containing the synchronization
    sequences were mixed up using a signal of $n\si{\percent}$ the
    baseband nyquist frequency resulting in a cyclic frequency shift.
    The results are shown in figure \ref{img:results_time_sync_freq}.

    \figurizefile{diagrams/results_time_sync_freq.tex}
                 {img:results_time_sync_freq}
                 {Detection time distributions for different frequency ofssets}
                 {1}{H}

    Figure \ref{img:results_time_sync_freq} shows that none of the
    methods express any dependency on cyclic frequency shifts.
    This is to be expected as none of the methods actually use
    the absolute frequency information contained in the preambles
    for timing synchronization.
  \end{subsubchapter}

  \begin{subsubchapter}{Frequency-selective channel}
    A major application for multi-carrier based techniques
    are transmissions over frequency-selective channels
    like reflection-heavy urban areas.

    Good performance in these usecases is thus also a
    requirement for multi-carrier synchronization systems.

    To characterize the performance of the synchronization
    methods at hand a selection of increasingly hostile
    channels were constructing different impulse responses.

    The frequency responses of these channels are shown
    in the linear plots in figure \ref{img:time_sync_combat_channels}.

    \figurizefile{diagrams/time_sync_combat_channels.tex}
                 {img:time_sync_combat_channels}
                 {Channel models used in the simulation}
                 {0.7}{H}

    The first channel was completely flat, the impulse resonse
    consisted of only a single dirac impulse.

    The second channel roughly resembled the behavior of
    an indoor communication with a direct line of sight.
    The impulse response consisted of a large peak, representing the
    direct line of sight, followed by gradual falloff and a
    highly attenuated reflection pulse.

    The remaining channels were intentionally designed to
    be hostile by placing large peaks in the impulse response
    over a wide span of time.

    The results of using the different algorithms, when used over these
    channels, are shown in figure \ref{img:results_time_sync_chan}.

    \figurizefile{diagrams/results_time_sync_chan.tex}
                 {img:results_time_sync_chan}
                 {Detection time distributions for different channel models}
                 {1}{H}

    % TODO: stuff

    \end{subsubchapter}
\end{subchapter}

\begin{subchapter}{\Acrlong{cfo} estimation}
  \figurizegraphic{diagrams/time_sync_hw_sloped.pdf}
                  {img:time_sync_hw_sloped}
                  {Estimated $f_\text{c}$ versus actual $f_\text{c}$}
                  {0.8}{H}

  \figurizegraphic{diagrams/time_sync_hw_horiz.pdf}
                  {img:time_sync_hw_horiz}
                  {Estimation error $\Delta f_\text{c}$ versus $f_\text{c}$}
                  {0.8}{H}
\end{subchapter}

\begin{subchapter}{\Acrshort{cpu} load}
  \begin{table}[H]
    \centering
    \begin{tabular}{| l | c | c |}
      \hline
      Processor & Benchmark samplerate & Baseline samplerate \\

      \hline
      \parbox[c]{5cm}{\vspace{1mm} AMD Ryzen 5 - 1600 \\ 6 \acrshort{cpu} cores \\ $\SI{3.4}{\giga\hertz}$ \\ Linux 4.13.12-1-ARCH \vspace{1mm}} &
      \parbox[c]{5cm}{\centering $114 - \SI{133}{\mega\sample\per\second}$} &
      \parbox[c]{5cm}{\centering $190 - \SI{198}{\mega\sample\per\second}$} \\

      \hline
      \parbox[c]{5cm}{\vspace{1mm} Intel Atom x5-Z8350 \\ 4 \acrshort{cpu} cores \\ $\SI{1.6}{\giga\hertz}$ \\ Linux 4.13.12-1-ARCH \vspace{1mm}} &
      \parbox[c]{5cm}{\centering $19 - \SI{20}{\mega\sample\per\second}$} &
      \parbox[c]{5cm}{\centering $33 - \SI{34}{\mega\sample\per\second}$} \\

      \hline
    \end{tabular}
    \caption{achievable samplerates for different processors}
    \label{tab:cpuload}
  \end{table}
\end{subchapter}
