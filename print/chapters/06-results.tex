In order to analyze the performance of the GNURadio blocks
discussed earlier a set of testcases were devised.

The metrics that the testcases were designed to test
were, firstly, the precision of the tag-placement in
the time domain in the presence of different disturbances,
secondly, the precision of the \gls{cfo} estimation
and finally the effective computational complexity.

\begin{subchapter}{Start-of-frame detection}
  The first testcase was designed to measures the quality
  of synchronisation when the signal is disturbed by,
  noise, frequency offsets or frequency selective channels.
  The respective results are shown in Figures \ref{img:results_time_sync_nois}
  to \ref{img:results_time_sync_chan}. \\

  \noindent All of these figures compare three different synchronization
  techniques:

  \begin{description}
    \item[Schmidl \& Cox:]
      The \acrlong{schcox} Correlator and Tagger, as discussed in the
      previous chapters.
      The Cross-correlation tagger component was not used in these tests.

    \item[Burst \& Silence:]
      A custom GNURadio block that detects a burst in input power
      followed by an equally long period of silence by calculating the
      average signal power in two consecutive windows and subtracting the
      energy in the later window from the energy of the earlier window.

      The noise floor affects both windows in a roughly equal manner
      and is thus canceled out.

    \item[Frequency Sweep:]
      Another custom GNURadio block that mixes the input signal
      with a repeating frequency sweep.

      The synchronization sequency consists of a complementary
      frequency sweep, such that the mixing of both will result
      in a constant frequency output.

      The constant frequency results in a constant phase difference
      between consecutive samples that is used for detection.
  \end{description}

  The algorithms were tested under these common conditions:

  \begin{itemize}
    \item
      The preambles were followed by random \gls{ofdm} symbols

    \item
      Each algortihm used a preamble of 512 symbols

    \item
      The energy of the whole preamble was equal for each
      algorithm and equal to the average energy of the \gls{ofdm}
      symbols
  \end{itemize}

  \begin{subsubchapter}{AWGN Channel}
    Figure \ref{img:results_time_sync_nois} shows the effect of
    different \acrshortpl{snr} on the output of the synchronization
    methods.
    The histograms show the distribution of tag positions
    relative to the actual position of the synchronization
    sequence.
    For a perfect synchronization method the histogram would
    show a single peak in the ``$0$'' bin, indicating that every
    synchronization sequence was detected without even a single
    sample of offset.

    A particulary bad method would show a single peak in the
    ``missed'' bin, indicating that the sequence was missed by
    more than ten samples or not detected at all.

    \figurizefile{diagrams/results_time_sync_nois.tex}
                 {img:results_time_sync_nois}
                 {Detection time distributions for different \acrshortpl{snr}}
                 {1}{H}

    For high \glspl{snr} all of the tested methods produced
    usable results - tagging most preambles to within a few
    samples.

    For decreasing \glspl{snr} the results obtained by the
    frequency sweep based method degraded rather quickly,
    already missing most
    preambles at an \gls{snr} of just $\SI{0}{\deci\bel}$
    while the other methods still provided reliable output.

    The best method in this test was the rather simple
    power-level based Burst \& Silence detector, dominating
    over the more complex Schmidl \& Cox detector.
    It should be noted however that the detection hysteresis levels
    for all methods were tweaked to produce a minimal amount
    of false positives at low noise levels.

    When tweaking the parameters for different design criteria
    e.g. a minimal amount of false negatives the Schmidl \& Cox
    and Burst \& Silence show similar performance while
    the frequency sweep based approach always provides inferior
    results.
  \end{subsubchapter}

  \begin{subsubchapter}{Frequency offset}
    The second test was designed to test the effect a frequency offset
    between transmitters and receivers has on the detection accuracy
    of the respective algorithms.

    In this test the baseband signals containing the synchronization
    sequences were mixed up using a signal of $n\si{\percent}$ the
    baseband nyquist frequency resulting in a cyclic frequency shift.
    The results are shown in figure \ref{img:results_time_sync_freq}.

    \figurizefile{diagrams/results_time_sync_freq.tex}
                 {img:results_time_sync_freq}
                 {Detection time distributions for different frequency ofssets}
                 {1}{H}

    Figure \ref{img:results_time_sync_freq} shows that none of the
    methods express any dependency on cyclic frequency shifts.
    This is to be expected as none of the methods actually use
    the absolute frequency information contained in the preambles
    for timing synchronization.
  \end{subsubchapter}

  \begin{subsubchapter}{Frequency-selective channel}
    A major application for multi-carrier based techniques
    are transmissions over frequency-selective channels
    like reflection-heavy urban areas.

    Good performance in these use-cases is thus also a
    requirement for multi-carrier synchronization systems.

    To characterize the performance of the synchronization
    methods at hand a selection of increasingly hostile
    channels were constructed by designing different
    impulse responses.

    The frequency responses of these channels are shown
    in the linear plots in figure \ref{img:time_sync_combat_channels}.

    \figurizefile{diagrams/time_sync_combat_channels.tex}
                 {img:time_sync_combat_channels}
                 {Channel models used in the simulation}
                 {0.7}{H}

    The first channel was completely flat, the impulse response
    consisted of only a single pulse.

    The second channel roughly resembled the behavior of
    an indoor communication with a direct line of sight.
    The impulse response consisted of a large peak, representing the
    direct line of sight, followed by gradual falloff and a
    highly attenuated reflection pulse.

    The remaining channels were intentionally designed to
    be hostile by placing large peaks in the impulse response
    over a wide span of time.

    The results for the different algorithms, when used over these
    channels, are shown in figure \ref{img:results_time_sync_chan}.

    \figurizefile{diagrams/results_time_sync_chan.tex}
                 {img:results_time_sync_chan}
                 {Detection time distributions for different channel models}
                 {1}{H}

    Both custom synchronization techniques failed dramatically
    when used over frequency-selective channels.

    In the case of the Burst \& Silence detector verifying the
    plausibility of these results is quite simple as any
    additional non-zero value in the impulse response in addition
    to the main pulse leads to parts of the burst-half of the
    preamble ``bleeding'' into the silent-half, reducing the
    difference in energy between the windows.
  \end{subsubchapter}
\end{subchapter}

\begin{subchapter}{\Acrlong{cfo} estimation}
  In addition to the previously analyzed synchronization in time
  the \gls{schcox} algorithm also provides an estimation of
  the difference in carrier frequency between receiver and
  transmitter, the \acrfull{cfo}. \\

  As \gls{schcox} was the only method presented in this thesis
  providing a means of estimating the \gls{cfo}
  its performance was characterized separately. \\

  The test was designed as an actual-hardware test
  and used common audio hardware.
  A speaker and a microphone\footnote{Due to the lack of an actual
  microphone a headphone was used as a crude replacement}
  were placed on opposite
  sides of a small room an image showing the components used
  is shown in \autoref{img:hw_chan_setup}. The speaker periodically broadcasted
  \gls{schcox} preambles consisting of two 256 symbols long
  sequences, occupying a bandwith of $\SI{4410}{\hertz}$
  around a carrier of $\SI{4000}{\hertz}$.
  These preambles were received by the microphone and mixed
  down by an LO-frequency between $\SI{3985}{\hertz}$ and $\SI{4015}{\hertz}$
  the \gls{schcox} algorithm was then used to estimate
  this carrier-frequency offset of $\pm\SI{15}{\hertz}$.

  The playback volume was adjusted to the lowest level
  that still provided reliable preamble detection at the receiver.

  The results are shown in figure \ref{img:time_sync_hw_sloped},
  which depicts the estimated LO-frequencies over the
  actual LO-frequencies used to mix down the signal.
  The measurements are depicted as blue dots while a
  green line shows the identity mapping between estimated
  and actual frequencies.

  \figurizegraphic{images/hw_chan_setup.jpg}
                  {img:hw_chan_setup}
                  {Main hardware components used in the \acrshort{cfo} test}
                  {0.6}{h}

  \figurizegraphic{diagrams/time_sync_hw_sloped.pdf}
                  {img:time_sync_hw_sloped}
                  {Estimated $f_\text{c}$ versus actual $f_\text{c}$}
                  {0.8}{H}

  An obvious first observation is that for frequency offsets of
  more than about $\pm\SI{8}{\hertz}$ the estimated frequencies
  were widely off from the expected values.

  This is a direct result of using the output phase
  of the \gls{schcox} algorithm for frequency estimation,
  as the phase is periodic in $(-\pi, \pi]$ leading to
  ambiguities in the phase-to-frequency mapping.

  The maxium detectable frequency offset is thus
  a criterium in the design of a \gls{schcox}
  based system.

  To analyze the \gls{cfo} performance under the assumption
  of unambiguous frequency offsets the same measurements
  as in figure \ref{img:time_sync_hw_sloped} where plotted
  again, this time showing the error in frequency estimation
  plotted over the actual carrier frequency.
  The resulting diagram is shown in
  figure \ref{img:time_sync_hw_horiz}.
  The values were clipped to a range of $[-2, 2]$.

  \figurizegraphic{diagrams/time_sync_hw_horiz.pdf}
                  {img:time_sync_hw_horiz}
                  {Estimation error $\Delta f_\text{c}$ versus $f_\text{c}$}
                  {0.8}{H}

  The figure shows that the carrier frequencies were
  estimated to within a range of $\pm\SI{0.7}{\hertz}$.
  The carrier spacings in a multi-carrier system
  would have to be designed to tollerate these residual
  frequency offsets.
\end{subchapter}

\begin{subchapter}{\Acrshort{cpu} load}
  A major design goal of the \gls{schcox} implementation
  presentated in this thesis was processing speed on
  general-purpose computing hardware.
  To facilitate this goal various optimizations were
  made in the software implementation. \\

  To test the processing speed of the
  \gls{schcox} correlator and -tagger blocks
  a custom GNURadio block was implemented that repeatedly outputs
  a preset sequence over and over while keeping
  track of the number of samples produced per unit of time. \\

  The overall processing speed of a GNURadio program
  is determined by the slowest block in the flowgraph.
  This is usually a hardware device that is limited in
  the number of samples it produces by its sample rate.

  In the absence of hardware devices, meaning a pure
  simulation scenario, the flowgraph will run as fast
  as possible, only limited by the processing speed
  of the computing hardware. \\

  For this test the custom speed measuring block
  introduced earlier was tasked to output spurious
  \gls{schcox} sequences overlayed with gaussian noise.

  This measuring source was then connected to the
  \gls{schcox} correlator block in series with
  the \gls{schcox} tagger block.
  The outputs of the tagger were dumped using
  null sink blocks which do not perform any processing
  on their inputs and do not produce any output.

  This program was then executed on two reasonably
  recent computers, containing \glspl{cpu} designed
  with different use-cases in mind.

  The first \gls{cpu} is an AMD Ryzen 5 model intended
  for the mid-to-high range Desktop PC market where power
  consumption is a minor concern.
  It provides, among others, the \acrshort{avx2} group of instructions
  that allow processing multiple values in a single processor
  instruction (\acrshort{simd}).

  The second \gls{cpu} is an Intel Atom model intended
  for very low power laptop and tablet computers.
  To reduce the power consumption and die-area
  of this \gls{cpu} only the SSE to \acrshort{sse42} line of
  instructions were implemented instead of the
  more powerful \acrshort{avx2} \acrshort{simd} instruction present
  in the Desktop \gls{cpu}. \\

  The samplerates achieved in this test are shown
  in \autoref{tab:cpuload} in the ``Benchmark samplerate''
  column.

  \begin{table}[H]
    \centering
    \begin{tabular}{| l | c | c |}
      \hline
      Processor & Benchmark samplerate & Baseline samplerate \\

      \hline
      \parbox[c]{5cm}{\vspace{1mm} AMD Ryzen 5 - 1600 \\ 6 \acrshort{cpu} cores \\ $\SI{3.4}{\giga\hertz}$ \\ Linux 4.13.12-1-ARCH \vspace{1mm}} &
      \parbox[c]{5cm}{\centering $114 - \SI{133}{\mega\sample\per\second}$} &
      \parbox[c]{5cm}{\centering $190 - \SI{198}{\mega\sample\per\second}$} \\

      \hline
      \parbox[c]{5cm}{\vspace{1mm} Intel Atom x5-Z8350 \\ 4 \acrshort{cpu} cores \\ $\SI{1.6}{\giga\hertz}$ \\ Linux 4.13.12-1-ARCH \vspace{1mm}} &
      \parbox[c]{5cm}{\centering $19 - \SI{20}{\mega\sample\per\second}$} &
      \parbox[c]{5cm}{\centering $33 - \SI{34}{\mega\sample\per\second}$} \\

      \hline
    \end{tabular}
    \caption{achievable samplerates for different processors}
    \label{tab:cpuload}
  \end{table}

  The table also contains a ``Baseline samplerate'' column.
  This column contains the samplerates obtained when the flowgraph
  is executed without the \gls{schcox} blocks, leaving only
  the measuring source and the null sinks to dump the
  output samples.

  This baseline figure is used to verify that the
  processing speed is actually limited by the \gls{schcox} blocks.
  As the baseline samplerates were substantially larger
  than the bechmark rates it is relatively certain that
  the processing speed was indeed limited by the \gls{schcox} blocks
  and the measured performance was a characteristic of these blocks. \\

  Another observation the benchmarking allowed can be seen
  in \autoref{img:benchmarkhtop}: only a small number of the available
  processor cores were actually utilized by the benchmarking program
  (the processor utilization is shown in the topmost 12 bargraphs).

  \figurizegraphic{images/benchmark_htop.png}
                  {img:benchmarkhtop}
                  {Processor load while executing the benchmarking flowgraph}
                  {0.95}
                  {H}

  This is due to the correlator block and the tagger block running
  in a single thread each, allowing them to utilize at most
  a single processor core at once, respectively.

  While utilizing more \gls{cpu} cores could possibly
  result in a higher samplerate, the limitation to at most
  two cores used by \gls{schcox} components can
  also be seen as a feature, whereby the remaining cores
  may still be used for other processing blocks without
  negatively impacting the overall archievable samplerate.
\end{subchapter}
